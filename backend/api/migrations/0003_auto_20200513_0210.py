# Generated by Django 2.1.4 on 2020-05-13 02:10

from django.db import migrations, models
from django.conf import settings
import hashlib
import glob
import os

def checksum(file_path):
    """
    Computes the SHA256 checksum of a file.
    """
    BUF_SIZE = 65536    # chunk size
    checksum = hashlib.sha256()
    with open(file_path, 'rb') as fp:
        while True:
            chunk = fp.read(BUF_SIZE)
            if not chunk:
                break
            checksum.update(chunk)

    return checksum.hexdigest()


def import_dataset(apps, schema_editor):
    """
    Import images from the dataset into the database, preprocessing as needed.
    """
    # we can't import the Image model directly as it may be a newer
    # version than this migration expects, so we use the historical version.

    Image = apps.get_model("api", "Image")
    DATASET_PATH = ["backend", "dataset", "images/"]
    dataset_images = glob.glob(os.path.join(settings.BASE_DIR, *DATASET_PATH, "*.tiff"))
    dataset_images = dataset_images[:100]   # cap to first 100 images

    # for img in Image.objects.all():
    #     person.save()

    # for each image file, create a database entry
    print("\n\tAdding to database the entries for {} images found...".format(len(dataset_images)))
    for img_path in dataset_images:
        imgID = checksum(img_path)
        img = Image(imgID=imgID, location=img_path, annotations=[])
        img.save()


class Migration(migrations.Migration):

    initial = True

    dependencies = [
        ('api', '0002_image'),
    ]

    operations = [
        migrations.RunPython(import_dataset, reverse_code=migrations.RunPython.noop)
    ]
